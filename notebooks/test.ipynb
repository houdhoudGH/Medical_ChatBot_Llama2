{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f79a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943fad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdabbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664a585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be434a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d818ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f52829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7078943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f4a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nourg\\AppData\\Local\\Temp\\ipykernel_21304\\4238859041.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\nourg\\Documents\\VS_code\\Medical_ChatBot_Llama2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb92f301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d337cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nourg\\Documents\\VS_code\\Medical_ChatBot_Llama2\\.venv\\lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817d4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93cf047",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"medical-chatbot-llama2\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,   \n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23293f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = [str(uuid4()) for _ in range(len(text_chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfdc99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_store = PineconeVectorStore.from_texts(\n",
    "#    [t.page_content for t in text_chunks],\n",
    "#    embedding=embeddings,\n",
    "#    ids=uuids,\n",
    "#    index_name=index_name\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c25e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the existing vector store\n",
    "vector_store = PineconeVectorStore(\n",
    "    index=pc.Index(index_name),   \n",
    "    embedding=embeddings,        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04fd42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a helpful and knowledgeable **medical assistant chatbot**.  \n",
    "Your job is to answer the user's questions based only on the provided context, unless the question is a general greeting or basic small talk.\n",
    "\n",
    "### Instructions:\n",
    "1. If the question is about medicine or health:\n",
    "   - Use ONLY the information from the context below.\n",
    "   - If the context does not provide enough information, say:  \n",
    "     \"I'm not sure about that based on my medical sources.\"\n",
    "   - Do NOT invent or make up answers.\n",
    "\n",
    "2. If the user greets you or asks something simple like \"hi\", \"hello\", \"how are you\", or \"who are you\":\n",
    "   - Respond naturally as a friendly medical assistant.  \n",
    "   Example: \"Hello! I'm your medical assistant. How can I help you today?\"\n",
    "\n",
    "3. If the user asks something completely unrelated to medicine:\n",
    "   - Politely say you can only help with medical or health-related questions.\n",
    "\n",
    "---\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Helpful answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9917ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6fd0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"../model/llama-2-7b-chat.ggmlv3.q2_K.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee6ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb2007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd22a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: what causes a heart attack?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (600) exceeded maximum context length (512).\n",
      "Number of tokens (601) exceeded maximum context length (512).\n",
      "Number of tokens (602) exceeded maximum context length (512).\n",
      "Number of tokens (603) exceeded maximum context length (512).\n",
      "Number of tokens (604) exceeded maximum context length (512).\n",
      "Number of tokens (605) exceeded maximum context length (512).\n",
      "Number of tokens (606) exceeded maximum context length (512).\n",
      "Number of tokens (607) exceeded maximum context length (512).\n",
      "Number of tokens (608) exceeded maximum context length (512).\n",
      "Number of tokens (609) exceeded maximum context length (512).\n",
      "Number of tokens (610) exceeded maximum context length (512).\n",
      "Number of tokens (611) exceeded maximum context length (512).\n",
      "Number of tokens (612) exceeded maximum context length (512).\n",
      "Number of tokens (613) exceeded maximum context length (512).\n",
      "Number of tokens (614) exceeded maximum context length (512).\n",
      "Number of tokens (615) exceeded maximum context length (512).\n",
      "Number of tokens (616) exceeded maximum context length (512).\n",
      "Number of tokens (617) exceeded maximum context length (512).\n",
      "Number of tokens (618) exceeded maximum context length (512).\n",
      "Number of tokens (619) exceeded maximum context length (512).\n",
      "Number of tokens (620) exceeded maximum context length (512).\n",
      "Number of tokens (621) exceeded maximum context length (512).\n",
      "Number of tokens (622) exceeded maximum context length (512).\n",
      "Number of tokens (623) exceeded maximum context length (512).\n",
      "Number of tokens (624) exceeded maximum context length (512).\n",
      "Number of tokens (625) exceeded maximum context length (512).\n",
      "Number of tokens (626) exceeded maximum context length (512).\n",
      "Number of tokens (627) exceeded maximum context length (512).\n",
      "Number of tokens (628) exceeded maximum context length (512).\n",
      "Number of tokens (629) exceeded maximum context length (512).\n",
      "Number of tokens (630) exceeded maximum context length (512).\n",
      "Number of tokens (631) exceeded maximum context length (512).\n",
      "Number of tokens (632) exceeded maximum context length (512).\n",
      "Number of tokens (633) exceeded maximum context length (512).\n",
      "Number of tokens (634) exceeded maximum context length (512).\n",
      "Number of tokens (635) exceeded maximum context length (512).\n",
      "Number of tokens (636) exceeded maximum context length (512).\n",
      "Number of tokens (637) exceeded maximum context length (512).\n",
      "Number of tokens (638) exceeded maximum context length (512).\n",
      "Number of tokens (639) exceeded maximum context length (512).\n",
      "Number of tokens (640) exceeded maximum context length (512).\n",
      "Number of tokens (641) exceeded maximum context length (512).\n",
      "Number of tokens (642) exceeded maximum context length (512).\n",
      "Number of tokens (643) exceeded maximum context length (512).\n",
      "Number of tokens (644) exceeded maximum context length (512).\n",
      "Number of tokens (645) exceeded maximum context length (512).\n",
      "Number of tokens (646) exceeded maximum context length (512).\n",
      "Number of tokens (647) exceeded maximum context length (512).\n",
      "Number of tokens (648) exceeded maximum context length (512).\n",
      "Number of tokens (649) exceeded maximum context length (512).\n",
      "Number of tokens (650) exceeded maximum context length (512).\n",
      "Number of tokens (651) exceeded maximum context length (512).\n",
      "Number of tokens (652) exceeded maximum context length (512).\n",
      "Number of tokens (653) exceeded maximum context length (512).\n",
      "Number of tokens (654) exceeded maximum context length (512).\n",
      "Number of tokens (655) exceeded maximum context length (512).\n",
      "Number of tokens (656) exceeded maximum context length (512).\n",
      "Number of tokens (657) exceeded maximum context length (512).\n",
      "Number of tokens (658) exceeded maximum context length (512).\n",
      "Number of tokens (659) exceeded maximum context length (512).\n",
      "Number of tokens (660) exceeded maximum context length (512).\n",
      "Number of tokens (661) exceeded maximum context length (512).\n",
      "Number of tokens (662) exceeded maximum context length (512).\n",
      "Number of tokens (663) exceeded maximum context length (512).\n",
      "Number of tokens (664) exceeded maximum context length (512).\n",
      "Number of tokens (665) exceeded maximum context length (512).\n",
      "Number of tokens (666) exceeded maximum context length (512).\n",
      "Number of tokens (667) exceeded maximum context length (512).\n",
      "Number of tokens (668) exceeded maximum context length (512).\n",
      "Number of tokens (669) exceeded maximum context length (512).\n",
      "Number of tokens (670) exceeded maximum context length (512).\n",
      "Number of tokens (671) exceeded maximum context length (512).\n",
      "Number of tokens (672) exceeded maximum context length (512).\n",
      "Number of tokens (673) exceeded maximum context length (512).\n",
      "Number of tokens (674) exceeded maximum context length (512).\n",
      "Number of tokens (675) exceeded maximum context length (512).\n",
      "Number of tokens (676) exceeded maximum context length (512).\n",
      "Number of tokens (677) exceeded maximum context length (512).\n",
      "Number of tokens (678) exceeded maximum context length (512).\n",
      "Number of tokens (679) exceeded maximum context length (512).\n",
      "Number of tokens (680) exceeded maximum context length (512).\n",
      "Number of tokens (681) exceeded maximum context length (512).\n",
      "Number of tokens (682) exceeded maximum context length (512).\n",
      "Number of tokens (683) exceeded maximum context length (512).\n",
      "Number of tokens (684) exceeded maximum context length (512).\n",
      "Number of tokens (685) exceeded maximum context length (512).\n",
      "Number of tokens (686) exceeded maximum context length (512).\n",
      "Number of tokens (687) exceeded maximum context length (512).\n",
      "Number of tokens (688) exceeded maximum context length (512).\n",
      "Number of tokens (689) exceeded maximum context length (512).\n",
      "Number of tokens (690) exceeded maximum context length (512).\n",
      "Number of tokens (691) exceeded maximum context length (512).\n",
      "Number of tokens (692) exceeded maximum context length (512).\n",
      "Number of tokens (693) exceeded maximum context length (512).\n",
      "Number of tokens (694) exceeded maximum context length (512).\n",
      "Number of tokens (695) exceeded maximum context length (512).\n",
      "Number of tokens (696) exceeded maximum context length (512).\n",
      "Number of tokens (697) exceeded maximum context length (512).\n",
      "Number of tokens (698) exceeded maximum context length (512).\n",
      "Number of tokens (699) exceeded maximum context length (512).\n",
      "Number of tokens (700) exceeded maximum context length (512).\n",
      "Number of tokens (701) exceeded maximum context length (512).\n",
      "Number of tokens (702) exceeded maximum context length (512).\n",
      "Number of tokens (703) exceeded maximum context length (512).\n",
      "Number of tokens (704) exceeded maximum context length (512).\n",
      "Number of tokens (705) exceeded maximum context length (512).\n",
      "Number of tokens (706) exceeded maximum context length (512).\n",
      "Number of tokens (707) exceeded maximum context length (512).\n",
      "Number of tokens (708) exceeded maximum context length (512).\n",
      "Number of tokens (709) exceeded maximum context length (512).\n",
      "Number of tokens (710) exceeded maximum context length (512).\n",
      "Number of tokens (711) exceeded maximum context length (512).\n",
      "Number of tokens (712) exceeded maximum context length (512).\n",
      "Number of tokens (713) exceeded maximum context length (512).\n",
      "Number of tokens (714) exceeded maximum context length (512).\n",
      "Number of tokens (715) exceeded maximum context length (512).\n",
      "Number of tokens (716) exceeded maximum context length (512).\n",
      "Number of tokens (717) exceeded maximum context length (512).\n",
      "Number of tokens (718) exceeded maximum context length (512).\n",
      "Number of tokens (719) exceeded maximum context length (512).\n",
      "Number of tokens (720) exceeded maximum context length (512).\n",
      "Number of tokens (721) exceeded maximum context length (512).\n",
      "Number of tokens (722) exceeded maximum context length (512).\n",
      "Number of tokens (723) exceeded maximum context length (512).\n",
      "Number of tokens (724) exceeded maximum context length (512).\n",
      "Number of tokens (725) exceeded maximum context length (512).\n",
      "Number of tokens (726) exceeded maximum context length (512).\n",
      "Number of tokens (727) exceeded maximum context length (512).\n",
      "Number of tokens (728) exceeded maximum context length (512).\n",
      "Number of tokens (729) exceeded maximum context length (512).\n",
      "Number of tokens (730) exceeded maximum context length (512).\n",
      "Number of tokens (731) exceeded maximum context length (512).\n",
      "Number of tokens (732) exceeded maximum context length (512).\n",
      "Number of tokens (733) exceeded maximum context length (512).\n",
      "Number of tokens (734) exceeded maximum context length (512).\n",
      "Number of tokens (735) exceeded maximum context length (512).\n",
      "Number of tokens (736) exceeded maximum context length (512).\n",
      "Number of tokens (737) exceeded maximum context length (512).\n",
      "Number of tokens (738) exceeded maximum context length (512).\n",
      "Number of tokens (739) exceeded maximum context length (512).\n",
      "Number of tokens (740) exceeded maximum context length (512).\n",
      "Number of tokens (741) exceeded maximum context length (512).\n",
      "Number of tokens (742) exceeded maximum context length (512).\n",
      "Number of tokens (743) exceeded maximum context length (512).\n",
      "Number of tokens (744) exceeded maximum context length (512).\n",
      "Number of tokens (745) exceeded maximum context length (512).\n",
      "Number of tokens (746) exceeded maximum context length (512).\n",
      "Number of tokens (747) exceeded maximum context length (512).\n",
      "Number of tokens (748) exceeded maximum context length (512).\n",
      "Number of tokens (749) exceeded maximum context length (512).\n",
      "Number of tokens (750) exceeded maximum context length (512).\n",
      "Number of tokens (751) exceeded maximum context length (512).\n",
      "Number of tokens (752) exceeded maximum context length (512).\n",
      "Number of tokens (753) exceeded maximum context length (512).\n",
      "Number of tokens (754) exceeded maximum context length (512).\n",
      "Number of tokens (755) exceeded maximum context length (512).\n",
      "Number of tokens (756) exceeded maximum context length (512).\n",
      "Number of tokens (757) exceeded maximum context length (512).\n",
      "Number of tokens (758) exceeded maximum context length (512).\n",
      "Number of tokens (759) exceeded maximum context length (512).\n",
      "Number of tokens (760) exceeded maximum context length (512).\n",
      "Number of tokens (761) exceeded maximum context length (512).\n",
      "Number of tokens (762) exceeded maximum context length (512).\n",
      "Number of tokens (763) exceeded maximum context length (512).\n",
      "Number of tokens (764) exceeded maximum context length (512).\n",
      "Number of tokens (765) exceeded maximum context length (512).\n",
      "Number of tokens (766) exceeded maximum context length (512).\n",
      "Number of tokens (767) exceeded maximum context length (512).\n",
      "Number of tokens (768) exceeded maximum context length (512).\n",
      "Number of tokens (769) exceeded maximum context length (512).\n",
      "Number of tokens (770) exceeded maximum context length (512).\n",
      "Number of tokens (771) exceeded maximum context length (512).\n",
      "Number of tokens (772) exceeded maximum context length (512).\n",
      "Number of tokens (773) exceeded maximum context length (512).\n",
      "Number of tokens (774) exceeded maximum context length (512).\n",
      "Number of tokens (775) exceeded maximum context length (512).\n",
      "Number of tokens (776) exceeded maximum context length (512).\n",
      "Number of tokens (777) exceeded maximum context length (512).\n",
      "Number of tokens (778) exceeded maximum context length (512).\n",
      "Number of tokens (779) exceeded maximum context length (512).\n",
      "Number of tokens (780) exceeded maximum context length (512).\n",
      "Number of tokens (781) exceeded maximum context length (512).\n",
      "Number of tokens (782) exceeded maximum context length (512).\n",
      "Number of tokens (783) exceeded maximum context length (512).\n",
      "Number of tokens (784) exceeded maximum context length (512).\n",
      "Number of tokens (785) exceeded maximum context length (512).\n",
      "Number of tokens (786) exceeded maximum context length (512).\n",
      "Number of tokens (787) exceeded maximum context length (512).\n",
      "Number of tokens (788) exceeded maximum context length (512).\n",
      "Number of tokens (789) exceeded maximum context length (512).\n",
      "Number of tokens (790) exceeded maximum context length (512).\n",
      "Number of tokens (791) exceeded maximum context length (512).\n",
      "Number of tokens (792) exceeded maximum context length (512).\n",
      "Number of tokens (793) exceeded maximum context length (512).\n",
      "Number of tokens (794) exceeded maximum context length (512).\n",
      "Number of tokens (795) exceeded maximum context length (512).\n",
      "Number of tokens (796) exceeded maximum context length (512).\n",
      "Number of tokens (797) exceeded maximum context length (512).\n",
      "Number of tokens (798) exceeded maximum context length (512).\n",
      "Number of tokens (799) exceeded maximum context length (512).\n",
      "Number of tokens (800) exceeded maximum context length (512).\n",
      "Number of tokens (801) exceeded maximum context length (512).\n",
      "Number of tokens (802) exceeded maximum context length (512).\n",
      "Number of tokens (803) exceeded maximum context length (512).\n",
      "Number of tokens (804) exceeded maximum context length (512).\n",
      "Number of tokens (805) exceeded maximum context length (512).\n",
      "Number of tokens (806) exceeded maximum context length (512).\n",
      "Number of tokens (807) exceeded maximum context length (512).\n",
      "Number of tokens (808) exceeded maximum context length (512).\n",
      "Number of tokens (809) exceeded maximum context length (512).\n",
      "Number of tokens (810) exceeded maximum context length (512).\n",
      "Number of tokens (811) exceeded maximum context length (512).\n",
      "Number of tokens (812) exceeded maximum context length (512).\n",
      "Number of tokens (813) exceeded maximum context length (512).\n",
      "Number of tokens (814) exceeded maximum context length (512).\n",
      "Number of tokens (815) exceeded maximum context length (512).\n",
      "Number of tokens (816) exceeded maximum context length (512).\n",
      "Number of tokens (817) exceeded maximum context length (512).\n",
      "Number of tokens (818) exceeded maximum context length (512).\n",
      "Number of tokens (819) exceeded maximum context length (512).\n",
      "Number of tokens (820) exceeded maximum context length (512).\n",
      "Number of tokens (821) exceeded maximum context length (512).\n",
      "Number of tokens (822) exceeded maximum context length (512).\n",
      "Number of tokens (823) exceeded maximum context length (512).\n",
      "Number of tokens (824) exceeded maximum context length (512).\n",
      "Number of tokens (825) exceeded maximum context length (512).\n",
      "Number of tokens (826) exceeded maximum context length (512).\n",
      "Number of tokens (827) exceeded maximum context length (512).\n",
      "Number of tokens (828) exceeded maximum context length (512).\n",
      "Number of tokens (829) exceeded maximum context length (512).\n",
      "Number of tokens (830) exceeded maximum context length (512).\n",
      "Number of tokens (831) exceeded maximum context length (512).\n",
      "Number of tokens (832) exceeded maximum context length (512).\n",
      "Number of tokens (833) exceeded maximum context length (512).\n",
      "Number of tokens (834) exceeded maximum context length (512).\n",
      "Number of tokens (835) exceeded maximum context length (512).\n",
      "Number of tokens (836) exceeded maximum context length (512).\n",
      "Number of tokens (837) exceeded maximum context length (512).\n",
      "Number of tokens (838) exceeded maximum context length (512).\n",
      "Number of tokens (839) exceeded maximum context length (512).\n",
      "Number of tokens (840) exceeded maximum context length (512).\n",
      "Number of tokens (841) exceeded maximum context length (512).\n",
      "Number of tokens (842) exceeded maximum context length (512).\n",
      "Number of tokens (843) exceeded maximum context length (512).\n",
      "Number of tokens (844) exceeded maximum context length (512).\n",
      "Number of tokens (845) exceeded maximum context length (512).\n",
      "Number of tokens (846) exceeded maximum context length (512).\n",
      "Number of tokens (847) exceeded maximum context length (512).\n",
      "Number of tokens (848) exceeded maximum context length (512).\n",
      "Number of tokens (849) exceeded maximum context length (512).\n",
      "Number of tokens (850) exceeded maximum context length (512).\n",
      "Number of tokens (851) exceeded maximum context length (512).\n",
      "Number of tokens (852) exceeded maximum context length (512).\n",
      "Number of tokens (853) exceeded maximum context length (512).\n",
      "Number of tokens (854) exceeded maximum context length (512).\n",
      "Number of tokens (855) exceeded maximum context length (512).\n",
      "Number of tokens (856) exceeded maximum context length (512).\n",
      "Number of tokens (857) exceeded maximum context length (512).\n",
      "Number of tokens (858) exceeded maximum context length (512).\n",
      "Number of tokens (859) exceeded maximum context length (512).\n",
      "Number of tokens (860) exceeded maximum context length (512).\n",
      "Number of tokens (861) exceeded maximum context length (512).\n",
      "Number of tokens (862) exceeded maximum context length (512).\n",
      "Number of tokens (863) exceeded maximum context length (512).\n",
      "Number of tokens (864) exceeded maximum context length (512).\n",
      "Number of tokens (865) exceeded maximum context length (512).\n",
      "Number of tokens (866) exceeded maximum context length (512).\n",
      "Number of tokens (867) exceeded maximum context length (512).\n",
      "Number of tokens (868) exceeded maximum context length (512).\n",
      "Number of tokens (869) exceeded maximum context length (512).\n",
      "Number of tokens (870) exceeded maximum context length (512).\n",
      "Number of tokens (871) exceeded maximum context length (512).\n",
      "Number of tokens (872) exceeded maximum context length (512).\n",
      "Number of tokens (873) exceeded maximum context length (512).\n",
      "Number of tokens (874) exceeded maximum context length (512).\n",
      "Number of tokens (875) exceeded maximum context length (512).\n",
      "Number of tokens (876) exceeded maximum context length (512).\n",
      "Number of tokens (877) exceeded maximum context length (512).\n",
      "Number of tokens (878) exceeded maximum context length (512).\n",
      "Number of tokens (879) exceeded maximum context length (512).\n",
      "Number of tokens (880) exceeded maximum context length (512).\n",
      "Number of tokens (881) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: {'query': 'what causes a heart attack?', 'result': \"\\nA person's\\nThe patient 1:\\n\\n\\nAn actual heart attack has several ways, thank you have provided by:\\nOf course of the question\\nAtheros\\nan \\nAtheros. What is not Helpful\\nWhile\\nA heart attack and comments (usefuller:\\nIt does not available on a fellow will come from Experts:\\nAn actual heart muscle\\nThe heart attack occurs when you can cause an houring Questions\\nA person does not found in the question\\n\\n\\nAtheros:\\nAnother information is provided by a friend, Thank you want to this question. What do you are highly likely involves a question\\nAtheros\\nIf you need to the following pieces:\\nan in question is below\\nThe answer:\\nA heart attack may include references and Additional Question\\nA person does not Helpful Answered â€¢ Examples\\nA heart attack?\\nA person here, please. What do not possible or Comments\\nAtheros\\nTo\\nAthermalory Scribe content\\nAn actual heart attack?\\nI don's\\nA heart musclears\\nYou have been studied the question:\\nAnnot knowing the following pieces:\\nA person knows all parts needed, Thank you provided by\\nWhen does not known as of the question\\nThe patient info below.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"what causes a heart attack?\"\n",
    "print(\"Q:\", query)\n",
    "print(\"A:\", qa.invoke(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b09166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
